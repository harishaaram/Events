{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the libraries for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer # imports WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn # imports Wordnet corpus\n",
    "from nltk.corpus import sentiwordnet as swn # imports SentiWordNet\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer #imports the Vader module for analyzing sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the libraries for opening up the file and common processing tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'urllib2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-41071401cfb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpunctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'urllib2'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from IPython.display import display\n",
    "import string\n",
    "from string import punctuation\n",
    "import urllib2\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/140/140-0.txt\" #assigns a link to a variable\n",
    "data = urllib2.urlopen(url.encode('utf-8')).read() #opens up the link/file\n",
    "data = data.replace(\"\\r\\n\", \" \")\n",
    "data = re.sub('^(.*?)START OF THIS PROJECT GUTENBERG EBOOK', '', data) #removes Project Gutenberg metadata\n",
    "data = re.sub('End of the Project Gutenberg(.*?)$', '', data)#removes Project Gutenberg metadata\n",
    "data = unicode(data, errors=\"ignore\") # ignores encoding errors\n",
    "data[:10000]\n",
    "#Alternative texts to use\n",
    "#https://www.gutenberg.org/files/140/140-0.txt The Jungle by Upton Sinclair\n",
    "# https://www.gutenberg.org/files/1342/1342-0.txt Pride and Prejudice by Jane Austen\n",
    "#https://www.gutenberg.org/files/543/543-0.txt The Main Street by Sinclair Lewis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(data) #sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences[0:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning sentiment scores to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer() # calls SentimentIntensitAnalyzer function\n",
    "for sentence in sentences[100:150]: # for a sentence in a list of sentences\n",
    "        display (sentence) #display sentence\n",
    "        ss = sid.polarity_scores(sentence) #and assign a sentiment polarity score\n",
    "        for k in sorted(ss):        \n",
    "            display ('{0}: {1}, '.format(k, ss[k])) #format the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going a step deeper with sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a sentence that contains, for example, a particular named entity (e.g. location, person, organization) the following code establishes the polarity of adjectives ('JJ) or adverbs ('RB') in the sentence. \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "adj = [] # opens up an empty list to collect all the adjectives \n",
    "for i in sentences: # for each sentence in a list of sentences\n",
    "    if 'Chicago' in i: #if the sentence contains a particular named entity\n",
    "        for word, tag in nltk.pos_tag(nltk.word_tokenize(i)): #tokenize the sentence and assign part of speech for each word\n",
    "            if tag==\"JJ\": #check if the word is an adjective or adverb \"RB\" or superlative \"JJS\", or comparative \"JJR\"\n",
    "                try:\n",
    "                    word_lemma = lemmatizer.lemmatize(word) # lemmatize the word\n",
    "                    print (word_lemma)\n",
    "                    adj.append(str(word)) #add it to the adj list\n",
    "                    synset=list(swn.senti_synsets(word_lemma, \"a\"))[0] #get the most likely synset for that adjective, superlative, comparative or adverb and its sentiment scoring\n",
    "                    print (synset)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting most common adjectives or adverbs that are found in the vicinity of a particular named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj_di = collections.Counter(adj) #counting all the extracted adjectives and putting them in a dictionary structure\n",
    "adj_di.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wn.synsets('chicago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(wn.synset('chicago.n.01').definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chicago = wn.synset('chicago.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chicago.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
